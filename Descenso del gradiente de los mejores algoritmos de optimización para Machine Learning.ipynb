{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso de gradiente\n",
    "\n",
    "### ¿Qué es el algorimo del descenso del gradiente? \n",
    "\n",
    "El descenso de gradiente es un algoritmo de optimización muy genérico capaz de encontrar soluciones óptimas a una amplia gama de problemas. La idea general del descenso de gradiente es ajustar los parámetros de forma iterativa para minimizar una función de coste. Este algoritmo es uno de los mejores para entrar nuestros modelos de aprendizaje de máquina. \n",
    "\n",
    "**Para entenderlo mejor lo vamos a ejemplifcar de la siguiente forma:**\n",
    "\n",
    "Suponga que está perdido en las montañas en la densa obscuridad; solo puedes sentir la pendiente del suelo debajo de tus pies. Una buena estrategia para llegar rápidamente al fondo del valle es descender en dirección a la pendiente más pronunciada. Esto es exactamente lo que hace el descenso de gradiente: mide el gradiente local de la función de error con respecto al vector de parámetros $\\theta$ , y va en la dirección del gradiente descendente. Una vez que el gradiente es cero, ¡ha alcanzado un mínimo!\n",
    "\n",
    "Concretamente, comienza llenando $\\theta$ con valores aleatorios (esto se llama inicialización aleatoria), y luego lo mejora gradualmente, dando un pequeño paso a la vez, cada paso intentando disminuir la función de costo (por ejemplo, el Error Cuadrático Medio), hasta que el algoritmo converja al mínimo como se puede apreciar: \n",
    "\n",
    "![Fig 1](https://user-images.githubusercontent.com/63415652/121979546-fdda8880-cd4f-11eb-9647-1861012b30ea.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un parámetro importante en descenso de gradiente es el tamaño de los pasos, determinado por el hiperparámetro de tasa de aprendizaje. Si la tasa de aprendizaje es demasiado pequeña, entonces el algoritmo tendrá que pasar por muchas iteraciones para converger, lo que llevará mucho tiempo. Como lo podemos ver en el siguiente grafico con una taza de aprendizaje demasiada pequeña:\n",
    "\n",
    "\n",
    "![Fig 2](https://user-images.githubusercontent.com/63415652/121980793-34b19e00-cd52-11eb-9177-55207f471671.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, si la tasa de aprendizaje es demasiado alta, es posible que salte a través del valle y termine en el otro lado, posiblemente incluso más alto de lo que estaba antes. Esto puede hacer que el algoritmo diverja, con valores cada vez mayores, sin encontrar una buena solución: \n",
    "\n",
    "\n",
    "![Fig 3](https://user-images.githubusercontent.com/63415652/121981773-e43b4000-cd53-11eb-9125-860950347f31.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, no todas las funciones de coste se ven como buenos cuencos normales. Puede haber agujeros, crestas, mesetas y todo tipo de terrenos irregulares, lo que dificulta la convergencia al mínimo. El siguiente gráfico muestra los desafíos principales con el descenso de gradiente: si la inicialización aleatoria inicia el algoritmo de la izquierda, entonces convergerá a un mínimo local, que no es tan bueno como el mínimo global. Si comienza por la derecha, tomará mucho tiempo cruzar la meseta, y si se detiene demasiado pronto, nunca alcanzará el mínimo global.\n",
    "\n",
    "![fig 4](https://user-images.githubusercontent.com/63415652/121992603-96303780-cd67-11eb-8b84-c5728946bd33.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de la función de costo del Error Cuadrático Medio para un modelo de regresión lineal resulta ser una función convexa, lo que significa que, si elegimos dos puntos cualesquiera en la curva, el segmento de línea que los une nunca cruza la curva. Esto implica que no hay mínimos locales, solo un mínimo global. También es una función continua con una pendiente que nunca cambia abruptamente. Estos dos hechos tienen una gran consecuencia: se garantiza que el descenso del gradiente se acercará arbitrariamente al mínimo global (si esperamos lo suficiente y si la tasa de aprendizaje no es demasiado alta). \n",
    "\n",
    "De hecho, la función de costo tiene la forma de un cuenco, pero puede ser un cuenco alargado si las características tienen escalas muy diferentes. \n",
    "\n",
    "En conclusión, entrenar un modelo significa buscar una combinación de parámetros del modelo que minimice una función de costo (sobre el conjunto de entrenamiento). Es una búsqueda en el espacio de parámetros del modelo: cuantos más parámetros tiene un modelo, más dimensiones tiene este espacio y más difícil es la búsqueda: buscar una aguja en un pajar de 300 dimensiones es mucho más complicado que en tres dimensiones. Afortunadamente, dado que la función de costo es convexa en el caso de una regresión lineal, la aguja está simplemente en la parte inferior del cuenco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
