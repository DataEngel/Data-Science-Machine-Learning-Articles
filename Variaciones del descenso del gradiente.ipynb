{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso de gradiente completo \n",
    "\n",
    "Para implementar el descenso de gradiente completo, es necesario calcular el gradiente de la función de costo con respecto a cada parámetro del modelo $\\theta_{j}$. En otras palabras, debe calcular cuánto cambiará la función de costo si cambia $\\theta_{j}$ solo un poco. A esto se le llama derivada parcial. Es como preguntar \"¿Cuál es la pendiente de la montaña bajo mis pies si miro hacia el este?\" y luego hacer la misma pregunta mirando al norte (y así sucesivamente para todas las demás dimensiones, si puedes imaginar un universo con más de tres dimensiones). \n",
    "\n",
    "La ecuación:\n",
    "\n",
    "$\\frac{\\partial }{\\partial \\theta_{j}} MSE(\\theta)=\\frac{2}{m} \\sum\\limits_{i=1}^m (\\theta^{T}x^{(i)}-y^{(i)}) x_{j}^{(i)}$ \n",
    "\n",
    "calcula la derivada parcial de la función de costo con respecto al parámetro ${\\theta_{j}}$, anotado $ \\frac{\\partial}{\\partial \\theta_{j}} MSE(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de calcular estas derivadas parciales individualmente, puede usar la ecuación:\n",
    "\n",
    "$\\Delta_{\\theta} MSE(\\theta) = \\begin{pmatrix}\\frac{\\partial}{\\partial \\theta_{0}} MSE(\\theta) \\\\ \\frac{\\partial}{\\partial \\theta_{1}} MSE(\\theta) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial \\theta_{n}} MSE(\\theta) \\end{pmatrix} = \\frac{2}{m}X^{T}(X \\theta - y)$\n",
    "\n",
    "para calcularlas todas de una vez. El vector de gradiente, denominado $\\Delta_{\\theta} MSE(\\theta)$, contiene todas las derivadas parciales de la función de costo (una para cada parámetro del modelo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que esta fórmula implica cálculos sobre todo el conjunto de entrenamiento X, en cada paso del descenso de gradiente completo. Esta es la razón por la que el algoritmo se llama Descenso de gradiente completo: utiliza el lote completo de datos de entrenamiento en cada paso. Como resultado, es terriblemente lento en conjuntos de entrenamiento muy grandes (pero veremos algoritmos de descenso de gradiente mucho más rápidos en breve). Sin embargo, Gradient Descent se adapta bien al número de características; entrenar un modelo de regresión lineal cuando hay cientos de miles de características es mucho más rápido usando GradientDescent que usando la ecuación normal o la descomposición de SVD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenga el vector de gradiente, que apunta hacia arriba, simplemente vaya en la dirección opuesta para ir cuesta abajo. Esto significa restar $\\Delta_{\\theta}MSE(\\theta)$ de $\\theta$. Aquí es donde entra en juego la tasa de aprendizaje $η$: multiplique el vector de gradiente por &η& para determinar el tamaño del paso cuesta abajo como lo podemos apreciar en la siguiente ecuación: \n",
    "\n",
    "$\\theta^{(next \\hspace{0.1cm} step)} = \\theta - η \\Delta_{\\theta} MSE (\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo podemos saber la cantidad de iteraciones que nuestro algoritmo debe de dar? \n",
    "\n",
    "Debemos considerar que si es demasiado bajo, aún estará lejos de la solución óptima cuando el algoritmo se detenga, pero si es demasiado alto, perderá tiempo mientras los parámetros del modelo ya no cambian. Una solución simple es establecer una gran cantidad de iteraciones pero interrumpir el algoritmo cuando el vector de gradiente se vuelve pequeño, es decir, cuando su norma se vuelve más pequeña que un número de estaño ε (llamado tolerancia), porque esto sucede cuando el gradiente de descenso se ha reducido. (casi) alcanzó el mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de convergencia \n",
    "\n",
    "Cuando la función de costo es convexa y su pendiente no cambia abruptamente (como es el caso de la función de costo MSE), el descenso de gradiente por lotes con una tasa de aprendizaje fija eventualmente convergerá a la solución óptima, pero es posible que deba esperar un tiempo: tome O(1/ε) iteraciones para alcanzar el óptimo dentro de un rango de ε dependiendo de la forma de la función de costo. Si divide la tolerancia por 10 para tener una solución más precisa, es posible que el algoritmo deba ejecutarse unas 10 veces más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso de gradiente estocástico\n",
    "\n",
    "El principal problema con descenso de gradiente completo es el hecho de que utiliza todo el conjunto de entrenamiento para calcular los gradientes en cada paso, lo que lo hace muy lento cuando el conjunto de entrenamiento es grande. En el extremo opuesto, gradiente descendente estocástico simplemente elige una instancia aleatoria en el conjunto de entrenamiento en cada paso y calcula los gradientes basándose solo en esa instancia única. Obviamente, esto hace que el algoritmo sea mucho más rápido ya que tiene muy pocos datos para manipular en cada iteración. También hace posible entrenar en conjuntos de entrenamiento enormes, ya que solo una instancia debe estar en la memoria en cada iteración. \n",
    "\n",
    "Por otro lado, debido a su naturaleza estocástica (es decir, aleatoria), este algoritmo es mucho menos regular que descenso de gradiente completo: en lugar de disminuir suavemente hasta alcanzar el mínimo, la función de costo rebotará hacia arriba y hacia abajo, disminuyendo solo en promedio. Con el tiempo, terminará muy cerca del mínimo, pero una vez que llegue allí, seguirá rebotando, sin asentarse nunca. Entonces, una vez que se detiene el algoritmo, los valores finales de los parámetros son buenos, pero no óptimos. Como podemos ver a continuación: \n",
    "![fig5](https://user-images.githubusercontent.com/63415652/122492998-7e95c080-cfac-11eb-93b3-d7fd31e6ea55.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando la función de costo es muy irregular como esta: \n",
    "\n",
    "![fig 4](https://user-images.githubusercontent.com/63415652/122493257-febc2600-cfac-11eb-89bc-c6b0c5fac084.PNG)\n",
    "\n",
    "la cual vimos en el artículo de **introducción al descenso del gradiente**, esto puede ayudar a que el algoritmo salte de los mínimos locales, por lo que el Descenso de gradiente estocástico tiene más posibilidades de encontrar el mínimo global que el Descenso de gradiente por lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, la aleatoriedad es buena para escapar de los óptimos locales, pero mala porque significa que el algoritmo nunca puede establecerse en el mínimo. Una solución a este dilema es reducir gradualmente la tasa de aprendizaje. Los pasos comienzan siendo grandes (lo que ayuda a avanzar rápidamente y escapar de los mínimos locales), luego se hacen cada vez más pequeños, lo que permite que el algoritmo se establezca en el mínimo global. Este proceso es similar al algoritmo de recocido simulado, un algoritmo inspirado en el proceso de recocido en metalurgia donde el metal fundido se enfría lentamente. La función que determina la tasa de aprendizaje en cada iteración se llama programa de aprendizaje. Si la tasa de aprendizaje se reduce demasiado rápido, es posible que se quede atascado en un mínimo local o incluso termine congelado a la mitad del mínimo. Si la tasa de aprendizaje se reduce demasiado lentamente, puede saltar alrededor del mínimo durante mucho tiempo y terminar con una solución subóptima si detiene el entrenamiento demasiado pronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se usa Descenso de gradiente estocástico, las instancias de entrenamiento deben ser independientes y distribuidas de manera idéntica (IID), para garantizar que los parámetros se dirijan hacia el promedio global óptimo. Una forma sencilla de garantizar esto es mezclar las instancias durante el entrenamiento (por ejemplo, elegir cada instancia al azar o mezclar el conjunto de entrenamiento al comienzo de cada época). Si no hace esto, por ejemplo, si las instancias están ordenadas por etiqueta, entonces SGD comenzará a optimizar para una etiqueta, luego la siguiente, y así sucesivamente, y no se acercará al mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso de gradiente por lotes\n",
    "\n",
    "El último algoritmo de descenso del gradiente que veremos se llama descenso del gradiente por lotes pequeños. Es bastante simple de entender una vez que se conoce el descenso del gradiente completo y estocástico: en cada paso, en lugar de calcular los gradientes basados en el conjunto de entrenamiento completo (como en GD completo) o basados en una sola instancia (como en GD Estocástico), GD por lotes calcula los gradientes en pequeños conjuntos aleatorios de instancias llamados mini lotes. La principal ventaja de Mini-batch GD sobre Stochastic GD es que puede obtener un aumento de rendimiento a partir de la optimización del hardware de las operaciones matriciales, especialmente cuando se utilizan GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El progreso del algoritmo en el espacio de parámetros es menos errático que con SGD, especialmente con mini lotes bastante grandes. Como resultado, GD por lotes terminará caminando un poco más cerca del mínimo que SGD. Pero, por otro lado, puede ser más difícil escapar de los mínimos locales en el caso de problemas que sufren de mínimos locales, a diferencia de la Regresión lineal. \n",
    "\n",
    "![fig6](https://user-images.githubusercontent.com/63415652/122494542-2f04c400-cfaf-11eb-8dbe-4071c5454b6e.PNG)\n",
    "\n",
    "En el gráfico anterior nos muestra los caminos seguidos por los tres algoritmos de descenso de gradiente en el espacio de parámetros durante el entrenamiento. Todos terminan cerca del mínimo, pero el camino de GD completo en realidad se detiene en el mínimo, mientras que GD estocástico y GD por lotes continúan caminando. Sin embargo, no olvide que GD completo requiere mucho tiempo para dar cada paso, y GD estocástico y GD por lotes también alcanzarían el mínimo si utilizara un buen programa de aprendizaje."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
